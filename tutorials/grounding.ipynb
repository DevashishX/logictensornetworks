{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grounding in Logic Tensor Networks (LTN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LTN consists of a non-logical part (the signature) and logical connectives and quantifiers. \n",
    "* **constants** denote individuals from some space of real numbers $\\mathbb{R}^k$. We call this the **domain**\n",
    "* **functions** can be any mathematical function either pre-defined or learnable. Examples of functions can be distance functions, similarities etc. Functions can be defined using any computational graph in Tensorflow. They can be linear functions, Deep Neural Networks.\n",
    "* **predicates** are represented as functions that map from some n-ary domain to a real from $[0,1]$.\n",
    "* **connectives** are modeled using t-norms\n",
    "* **quantifiers** are based on domain sample aggregations\n",
    "\n",
    "This tutorial explains how these concepts are grounded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization. we need numpy and matplotlib\n",
    "# this tutorial uses the LTN wrapper\n",
    "import logging;logging.basicConfig(level=logging.INFO);\n",
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt; \n",
    "import tensorflow as tf;\n",
    "\n",
    "# adding parent directory to sys.path (ltnw is in parent dir)\n",
    "import sys, os\n",
    "sys.path.insert(0,os.path.normpath(os.path.join(os.path.abspath(''),os.path.pardir)))\n",
    "import logictensornetworks_wrapper as ltnw;\n",
    "ltnw.SESSION=tf.InteractiveSession() # we will use an interactive session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants \n",
    "Constants are grounded in some space of real numbers. Each constant $c$ is mapped to a point in $\\mathbb{R}^k$. So that $c^\\mathcal{G} \\in\\mathbb{R}^k$.\n",
    "Here we define $c^\\mathcal{G}=\\left<2.1,3\\right>$ and $d^\\mathcal{G}=\\left<3.4,1.5\\right>$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltnw.constant(\"c\",[2.1,3.]);\n",
    "ltnw.constant(\"d\",[3.4,1.5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LTN Constants are in the simplest case represented by Tensorflow constants (or in some cases by Tensorflow variables). That means we can query the value of some constant easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.1, 3. ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltnw.constant(\"c\").eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "LTN functions can be defined in any way. The following defines the grounding $\\mathcal{G}$ of the function $f$ as $f^\\mathcal{G}: \\mathbb{R}^2\\times \\mathbb{R}^2\\rightarrow \\mathbb{R}^2$, with \n",
    "* $f^\\mathcal{G}:\\vec{x},\\vec{y}\\mapsto \\vec{x} - \\vec{y}$ \n",
    "* for $\\vec{x},\\vec{y}\\in\\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltnw.function(\"f\",4,2,fun_definition=lambda x,y: x-y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LTN functions are just computational graphs that can be called with constants, other functions and variables (explained later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.3000002,  1.5      ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltnw.term(\"f(c,d)\").eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicates\n",
    "\n",
    "LTN Predicates are grounded in mappings that assign a value between zero and one to some n-ary space of input values. $P: \\mathbb{R}^k\\times \\mathbb{R}^k ... \\rightarrow \\mathbb{R}$. Predicates in LTN can be Neural Tensor Networks or any other function that achieves such a mapping. The following defines a predicate $P$ using the similarity to point $\\vec{\\mu}=\\left<2,3\\right>$ and $P^\\mathcal{G}:\\vec{x}\\mapsto \\exp(-\\|\\vec{x}-\\vec{\\mu} \\|^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu=tf.constant([2.,3.])\n",
    "ltnw.predicate(\"P\",2,pred_definition=lambda x: tf.exp(-tf.norm(tf.subtract(x,mu),axis=1)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicates are just computational graphs, so we can easily query them. We use `ltnw.formula` for creating the formula (a Tensorflow graph) from a string. Then we call `eval` to let Tensorflow evaluate the graph and produce the satisfiability value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9048375], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltnw.formula(\"P(c)\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12849975], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltnw.formula(\"P(d)\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02665139], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltnw.formula(\"P(f(c,d))\").eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectives\n",
    "\n",
    "LTN suppports various logical connectives\n",
    "* not: $\\sim$ (logical symbol $\\neg$)\n",
    "* and: $\\&$ (logical symbol $\\wedge$)\n",
    "* or: $|$ (logical symbol $\\vee$)\n",
    "* implication: $->$ (logical symbol $\\rightarrow$)\n",
    "\n",
    "These are grounded in Fuzzy Logic t-norms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09516251], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltnw.formula(\"~P(c)\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03333712], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltnw.formula(\"P(c)&P(d)\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltnw.formula(\"P(c)|P(d)\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15515113], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltnw.formula(\"~P(f(c,d))->P(d)\").eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifiers\n",
    "\n",
    "LTN suppports two quantifiers. In order to ground these, let's first introduce variables.\n",
    "\n",
    "LTN variables are sets of individuals/constants from a domain. By convention, we start variable labels with a question mark. The following defines two variables with 100 random samples each (from the domain). Notice that the set of values (i.e. individuals from the domain) for the two variables are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltnw.variable(\"?x\",np.random.uniform(0.,4.,(100,2)).astype(\"float32\"));\n",
    "ltnw.variable(\"?y\",np.random.uniform(0.,4.,(100,2)).astype(\"float32\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate the predicate $P$ for all $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltnw.ask(\"P(?x)\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then ask if for all points $x$, $y$, $P(f(x,y))$ is true. Notice that the outcome of this is a three dimensional tensor where each cell represents the satisfiability of $P(f(a,b))$ with $a\\in x$ and $b\\in y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltnw.ask(\"P(f(?x,?y))\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltnw.ask(\"P(f(?x,?y)) | ~P(?x)\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantifiers can be used to make statements about such three multidimensional tensors by essentially margining out variables. For instance, the following checks if $P(x)$ is true for all $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11074361], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltnw.ask(\"forall ?x: P(?x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if there exists a sample for which $P$ holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8691504], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltnw.ask(\"exists ?x: P(?x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
